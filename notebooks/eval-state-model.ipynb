{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdata\n",
    "\n",
    "sys.path.append('..')\n",
    "from agent.config import load_config, override_config\n",
    "from agent.state.model import Supervisor\n",
    "from agent.state.data import Dataset\n",
    "\n",
    "LOG_DIR = Path('../runs/2019-09-05T155134/')\n",
    "CONFIG_FILE = Path(LOG_DIR / 'agent_train_conf.yaml')\n",
    "CKPT_FILE = Path(LOG_DIR / 'encoder_ckpt/epoch_495.tar')\n",
    "DATA_DIR = Path('../data')\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.set_grad_enabled(False)\n",
    "\n",
    "conf = override_config(load_config(CONFIG_FILE), state={'num_workers': 4})\n",
    "ckpt = T.load(CKPT_FILE)\n",
    "\n",
    "if T.cuda.is_available() and T.backends.cudnn.is_available():\n",
    "    device = T.device('cuda')\n",
    "else:\n",
    "    device = T.device('cpu')\n",
    "\n",
    "model = Supervisor(conf.state, raw=False)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print(conf)\n",
    "print('')\n",
    "print(model)\n",
    "print('')\n",
    "print('total parameters:  ', sum(p.numel() for p in model.parameters()))\n",
    "print('encoder parameters:', sum(p.numel() for p in model.encoder.parameters()))\n",
    "print('convnet parameters:', sum(p.numel() for p in model.encoder._conv_net.parameters()))\n",
    "print('')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(DATA_DIR, conf)\n",
    "collate_fn = Dataset.CollateFn(np.ones((conf.state.num_target,)))\n",
    "loader = tdata.DataLoader(dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=conf.state.num_workers,\n",
    "                          collate_fn=collate_fn,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_decile_counts(class_out: np.ndarray) -> np.ndarray:\n",
    "    counts = np.ndarray((10,), dtype=np.int)\n",
    "    deciles = np.linspace(0, 1, 11)\n",
    "    # Include 1 in last decile\n",
    "    deciles[-1] += 0.01\n",
    "    for i, (start, stop) in enumerate(zip(deciles[:1], deciles[1:])):\n",
    "        counts[i] = np.count_nonzero(np.logical_and(start <= class_out, class_out < stop))\n",
    "    return counts\n",
    "\n",
    "def accuracy(cm: np.ndarray) -> float:\n",
    "    # (tn + tp) / (tn + fn + fp + tp)\n",
    "    return (cm[0,0] + cm[1,1]) / np.sum(cm)\n",
    "\n",
    "def precision(cm: np.ndarray) -> float:\n",
    "    # tp / (tp + fp)\n",
    "    denom = (cm[1,1] + cm[0,1])\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return cm[1,1] / denom\n",
    "\n",
    "def recall(cm: np.ndarray) -> float:\n",
    "    # tp / (tp + fn)\n",
    "    denom = cm[1,1] + cm[1,0]\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return cm[1,1] / denom\n",
    "\n",
    "def f1_score(cm: np.ndarray) -> float:\n",
    "    p = precision(cm)\n",
    "    r = recall(cm)\n",
    "    if p + r == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * (p * r) / (p + r)\n",
    "\n",
    "conf_matrices = np.zeros((conf.state.num_target, 2, 2), dtype=np.int64)\n",
    "out_deciles = np.zeros((conf.state.num_target, 10), dtype=np.int64)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    epoch_start = time.perf_counter()\n",
    "    for i, batch in enumerate(loader):\n",
    "        batch.to(device, non_blocking=True)\n",
    "        out = model(batch)\n",
    "        mse_raw = F.mse_loss(out, batch.target, reduction='none')\n",
    "        out_np = out.cpu().numpy()\n",
    "        pred_np = (out_np >= 0.5).astype(np.int)\n",
    "        target_np = batch.target.cpu().numpy()\n",
    "\n",
    "        for j in range(conf.state.num_target):\n",
    "            conf_matrices[j] += confusion_matrix(target_np[:,j], pred_np[:,j], labels=[0, 1])\n",
    "            out_deciles[j] += get_decile_counts(out_np[:,j])\n",
    "\n",
    "    d_time = round((time.perf_counter() - epoch_start) / 60, 2)\n",
    "    print('Epoch {} complete in {} m'.format(epoch, d_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i in range(conf.state.num_target):\n",
    "    cm = conf_matrices[i]\n",
    "    metrics.append([f1_score(cm), precision(cm), recall(cm), accuracy(cm)])\n",
    "\n",
    "df = pd.DataFrame(metrics, columns=['f1', 'precision', 'recall', 'accuracy'], index=Dataset.TARGET_COLS)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['f1'][df['f1'] > 0].median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:agent] *",
   "language": "python",
   "name": "conda-env-agent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
